{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2499,
     "status": "ok",
     "timestamp": 1639716784893,
     "user": {
      "displayName": "Jiongxin Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjlb8M2dExnffwT6hq2paV8pUPM7GEKoUCpTKD5=s64",
      "userId": "14451865628790522467"
     },
     "user_tz": 300
    },
    "id": "VrZ9pFODA3nU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date,timedelta\n",
    "import pandas_gbq\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "key = \"AIzaSyBZuIZi_OblHYl6n0dwX40W_5Harpp6wlk\"\n",
    "dataset = 'finalproject'\n",
    "project_id = 'big-data6893-335604'\n",
    "# table = \"testHotel\"\n",
    "\n",
    "food_lst = [\"bakery\",\"bar\",\"cafe\",\"restaurant\", \"meal_takeaway\"]\n",
    "play_lst = [\"library\", \"museum\", \"park\", \"shopping_mall\", \"zoo\"]\n",
    "searchType = [\"Hotel\", \"Food\", \"Play\"]\n",
    "\n",
    "rapidapi_host = \"hotels4.p.rapidapi.com\"\n",
    "rapidapi_key =  \"46facb3d8dmshb5e20b5bc84b439p1a9646jsn7b49c8952c8d\"\n",
    "no_hotel_lst = []\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    {\n",
    "    \"type\": \"service_account\",\n",
    "      \"project_id\": \"big-data6893-335604\",\n",
    "      \"private_key_id\": \"e647582ef782c12bbf63fc160d3ad6f854b7648f\",\n",
    "      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDxSG54mdW7SuF2\\nPnSYlOUx+bPicizjR55yN4hWnXBAjTmWjWet619XT5NIZwyDMCJZc37e1x++Xd83\\nnYzrIUvxgWPyRHyCkS65eWVLRoAzU66Xl1iwpMVCFP84ALJtwCvKVNSyTnU10eIB\\nGkL6L8ceyXoer05zac9ILDcXzqU77nFDdOSsAnWAYSeWdxQRo0wjk3KDk8zraDuf\\nvz/8eAW5G7eUchO1EDE5o/YaMq8knLZvixOmqkgY31njeN77H4ZKWEy8/RqpgQ1Y\\nPVSbXmiAnLCsE0jyuwUJ1T9dcj3R7C36U9bAwte1H9bSUjsIqt1CHz+OXnlpH8wG\\nvTtEH5SHAgMBAAECggEABhmPgr4E4MDHtWkRIosKcPp/7owgurg59xI/VffnTsJ4\\nlRKgbzhW8d/2+GrJLrHd/xvui6ytm+7x8I0rnbAlpDE3Y827xhiXMU+H3ODR5zpI\\n3NfnK+67y+wNow6ldCUvwOQ8d6uIcWK2eieopNGQu6RaptbwvqCLVybtrPeSRtMM\\n+a/503ajNlbGb7yOFoWu+tpVtJfSjW9jWGEjqE2/2E149p/hnaUfDV9ldegXfd4T\\nJyWLpjbA43elN1l8KuRE8oEzFEbwfw63o8pTmmZx/+lXfxGS1clqPGGJHQA+WCgG\\nu4S93DMjkxdPf9IKAU6EtCs/239iaWdBPMpTRvyZfQKBgQD77SONG5uTAQ1sa7CC\\nT1lYSE7cMJRTSbN9uT1k3MjX0KYunVxdVSjILAPTn+3IHKUW9YEX5R+e+A0qJM9/\\njw2SeKITyrycEb0uz1+dk+YF6J8c2IQ4zPd9ly8UVIYfNw4FrLmw1hPrJ53N2fs6\\nV9EPvPquXlOUKWFnM5B0WLKnFQKBgQD1Lzvc5CcfHv2z7dJ31y7ppzNMc/tbqwmT\\nrWrnwEMTUvIiH2kcjeLSYSw5qLexzuQFx9s/2wZ8Y4Nooa9ykyvbpbRuvuZSCt53\\nXwY9PS5qUM+ZRh5PanUCCGf6YkCO7LOh5ZgUuTbGTSVXAQMn1PONmcBp7eZkrTcY\\n4B5R2sh0KwKBgDlpHjvu+bIzgDKgC/Z2TL8Qo2AMdhDQ7+WLzFDq+54q/2QKGl1u\\npb+QQEL+5DpBROIJiqS+Y0lf7+gVwW+pUwd5FD58aiUK6dj8Cycm6DmafIAfW2py\\nU0g8ps70QChm7Hwgk6SX9KwXOCAMN/NgxdTXVS1dc6CFGZxiJN5OxE/NAoGAbKHR\\n5yvbPYmwpMDxaJGZwoKHUw9sRhBA/QJwBGCGF5C/oWjDXJhs8AOH4cAkK47cLsd/\\nGArGE+TPe1Nv9dbJLtd7WzoPuDgCm2cpz4ZFA2vsnx+XHF6xmwX4c9KGggzUBh5A\\nxKXPZAsYSTU0nbhXdNyziPuUAfVRHR9nr6K8/+MCgYEA29qXflDLYcRkzs+K2dwZ\\nZmnTOMLOIPnt+V0uvpK/16vBgBHj0DVsoeBuB2BS8JnQ6tPNZ/HUI1Ra5skIKxch\\nOAhmFXtiT1HjYwyUoJS7ncKlT9Mgy1nRinXIrlTi8S4E8JH3eyqhjYsLs/f5GwEJ\\nS++qwp32xda9PuwNJjY/+58=\\n-----END PRIVATE KEY-----\\n\",\n",
    "      \"client_email\": \"e6893final2@big-data6893-335604.iam.gserviceaccount.com\",\n",
    "      \"client_id\": \"101897899906931362112\",\n",
    "      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/e6893final2%40big-data6893-335604.iam.gserviceaccount.com\"\n",
    "},)\n",
    "\n",
    "os.chdir(\"..\")\n",
    "previous_path = os.path.abspath(os.getcwd())\n",
    "crime_path = previous_path + \"/crimedata/analysis/zipcode_saftylevel.csv\"\n",
    "twitter_path = previous_path + \"/twitter/attractions.csv\"\n",
    "\n",
    "def getHotelID(response,hotel_name,geo_pair):\n",
    "  total = response.json()\n",
    "  # print(total, hotel_name, geo_pair)\n",
    "  total = total[\"suggestions\"]\n",
    "  hotel = [e for e in total if e['group']=='HOTEL_GROUP'][0]\n",
    "  Find = False\n",
    "  if len(hotel[\"entities\"]) == 0:\n",
    "    print(\"Can't find hotel when name: \", hotel_name)\n",
    "    no_hotel_lst.append(hotel_name)\n",
    "    hotel_info = pd.DataFrame()\n",
    "    return Find, hotel_info\n",
    "  all_hotel = hotel[\"entities\"]\n",
    "  ID = []\n",
    "  name = []\n",
    "  geometric = []\n",
    "  for h in all_hotel:\n",
    "    ID.append(h[\"destinationId\"])\n",
    "    name.append(h[\"name\"])\n",
    "    geometric.append((float(\"{:.3f}\".format(h[\"latitude\"])),float(\"{:.3f}\".format(h[\"longitude\"]))))\n",
    "    if h[\"name\"] == hotel_name or geometric[-1] == geo_pair:\n",
    "      Find = True\n",
    "  hotel_info = pd.DataFrame({\"ID\":ID, \"name\":name, \"geometric\": geometric})\n",
    "  return Find, hotel_info\n",
    "\n",
    "def getHotelPrice(total,hotel_name):\n",
    "  #total = response.json()[\"price\"]\n",
    "  try:\n",
    "    rooms = total[\"body\"][\"roomsAndRates\"][\"rooms\"]\n",
    "    room_name = []\n",
    "    pricelst=[]\n",
    "    h_name = []\n",
    "    for room in rooms:\n",
    "      n = room[\"name\"]\n",
    "      price = room[\"ratePlans\"][0][\"price\"]['fullyBundledPricePerStay']\n",
    "      h_name.append(hotel_name)\n",
    "      room_name.append(n)\n",
    "      pricelst.append(price)\n",
    "    price_df = pd.DataFrame({\"name\": h_name,\"Room_type\":room_name,\"Price\":pricelst})\n",
    "    return price_df\n",
    "  except:\n",
    "    return pd.DataFrame\n",
    "\n",
    "def getresponse(hotel_name):\n",
    "\n",
    "  url = \"https://hotels4.p.rapidapi.com/locations/v2/search\"\n",
    "\n",
    "  querystring = {\"query\":\"New York,\"+hotel_name,\"locale\":\"en_US\",\"currency\":\"USD\"}\n",
    "  headers = {\n",
    "      'x-rapidapi-host': rapidapi_host,\n",
    "      'x-rapidapi-key': rapidapi_key\n",
    "      }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "  return response\n",
    "\n",
    "def getresponse2(id,checkIn, checkOut):\n",
    "\n",
    "  url = \"https://hotels4.p.rapidapi.com/properties/get-details\"\n",
    "\n",
    "  querystring = {\"id\":id,\"checkIn\":checkIn,\"checkOut\":checkOut,\"adults1\":\"1\",\"currency\":\"USD\",\"locale\":\"en_US\"}\n",
    "\n",
    "  headers = {\n",
    "      'x-rapidapi-host': rapidapi_host,\n",
    "      'x-rapidapi-key': rapidapi_key\n",
    "      }\n",
    "\n",
    "  response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "  return response\n",
    "\n",
    "def Zip2Loc(zip):\n",
    "  \"\"\"convert zipcode to lat ang lng\"\"\"\n",
    "  # Input:\n",
    "  # zip: string or int, key: string\n",
    "  # Output:\n",
    "  # location dictionary: {\"lat\":float, \"lng\":float}\n",
    "  url = 'https://maps.googleapis.com/maps/api/geocode/json?address='+str(zip)+'&key='+key\n",
    "  response = requests.get(url)\n",
    "  resp_json_payload = response.json()\n",
    "  return resp_json_payload['results'][0]['geometry']['location']\n",
    "\n",
    "def searchLodging(zip,r):\n",
    "  # r: radious (meters)\n",
    "  loc = Zip2Loc(zip)\n",
    "  url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=lodging&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "  response = requests.get(url)\n",
    "  resp_json_payload = response.json()\n",
    "  df = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "  while \"next_page_token\" in resp_json_payload:\n",
    "    time.sleep(3)\n",
    "    page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "    # url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=40.7999209%2C-73.96831019999999&radius=\"+\\\n",
    "    #     str(r)+\"&type=lodging&pagetoken=\"+page2_token+\"&key=AIzaSyBZuIZi_OblHYl6n0dwX40W_5Harpp6wlk\"\n",
    "    url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=lodging&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "\n",
    "    df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "    df = pd.concat([df,df2])\n",
    "\n",
    "  df = df.drop_duplicates(\"place_id\")\n",
    "  new_col = [name.replace(\".\",\"_\") for name in list(df.columns)]\n",
    "  df.set_axis(new_col,axis = 1, inplace = True)\n",
    "  return df\n",
    "  # return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "\n",
    "def getID(zip,r):\n",
    "  try:\n",
    "    hotel_info = pandas_gbq.read_gbq(\n",
    "    \"SELECT * FROM `finalproject.hotel_info`\",\n",
    "    project_id=project_id,credentials=credentials)\n",
    "  except:\n",
    "    hotel_info = pd.DataFrame()\n",
    "\n",
    "  df = searchLodging(zip,r)\n",
    "  df[\"geoID\"] = [\"None\" for _ in range(len(df))]\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    element = df.iloc[i]\n",
    "    h_name = element[\"name\"]\n",
    "    h_geo = (float(\"{:.3f}\".format(element[\"geometry_location_lat\"])), float(\"{:.3f}\".format(element[\"geometry_location_lng\"])))\n",
    "    # print(h_name,h_geo)\n",
    "    if hotel_info.empty:\n",
    "      print(\"Empty hotel info: use Hotel API Get hotel ID\")\n",
    "      if h_name in no_hotel_lst:\n",
    "        continue\n",
    "      response = getresponse(h_name)\n",
    "      Find, new_hotel_info = getHotelID(response,h_name,h_geo)\n",
    "      if Find:\n",
    "        if h_name in list(new_hotel_info[\"name\"]):\n",
    "          df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "        elif h_geo in list(new_hotel_info[\"geometric\"]):\n",
    "          df[\"geoID\"].iloc[i]= new_hotel_info[new_hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "      if new_hotel_info.empty:\n",
    "        continue\n",
    "      hotel_info = new_hotel_info\n",
    "    else:\n",
    "      # print(\"have hotel\")\n",
    "      if h_name in list(hotel_info[\"name\"]):\n",
    "        # print(\"Find same name\")\n",
    "        df[\"geoID\"].iloc[i] = hotel_info[hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "      elif h_geo in list(hotel_info[\"geometric\"]):\n",
    "        # print(\"Find same geo\")\n",
    "        df[\"geoID\"].iloc[i] = hotel_info[hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "      else:\n",
    "        print(\"use Hotel API Get hotel ID\", h_name)\n",
    "        # break\n",
    "        response = getresponse(h_name)\n",
    "        Find, new_hotel_info = getHotelID(response,h_name,h_geo)\n",
    "        if Find:\n",
    "          if (h_name in list(new_hotel_info[\"name\"])):\n",
    "            df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"name\"] == h_name][\"ID\"].iloc[0]\n",
    "          elif h_geo in list(new_hotel_info[\"geometric\"]):\n",
    "            df[\"geoID\"].iloc[i] = new_hotel_info[new_hotel_info[\"geometric\"] == h_geo][\"ID\"].iloc[0]\n",
    "        if new_hotel_info.empty:\n",
    "          continue\n",
    "        hotel_info = pd.concat([hotel_info, new_hotel_info]).drop_duplicates(\"name\")\n",
    "  return df, hotel_info\n",
    "\n",
    "def getAllPrice(df,checkIn, checkOut):\n",
    "  price_table = \"finalproject.HotelPrice_\"+checkIn\n",
    "  query = \"SELECT * FROM `\"+price_table+\"`\"\n",
    "  try:\n",
    "    price_df = pandas_gbq.read_gbq(\n",
    "    query,\n",
    "    project_id=project_id,credentials = credentials)\n",
    "  except:\n",
    "    price_df = pd.DataFrame()\n",
    "  for i in range(len(df)):\n",
    "    element = df.iloc[i]\n",
    "    h_id = element[\"geoID\"]\n",
    "    if h_id == \"None\":\n",
    "      continue\n",
    "    h_name = element[\"name\"]\n",
    "    if price_df.empty:\n",
    "      print(\"use Hotel API\")\n",
    "      response = getresponse2(h_id, checkIn, checkOut)\n",
    "      try:\n",
    "        total = response.json()[\"data\"]\n",
    "      except:\n",
    "        continue\n",
    "      tmp_price = getHotelPrice(total,h_name)\n",
    "      # if price_df.empty:\n",
    "      price_df = tmp_price\n",
    "      # else:\n",
    "      #   price_df = pd.concat([price_df, tmp_price])\n",
    "    else:\n",
    "      if h_name in list(price_df[\"name\"]):\n",
    "        continue\n",
    "      else:\n",
    "        print(\"use hotel API\")\n",
    "        response = getresponse2(h_id, checkIn, checkOut)\n",
    "        try:\n",
    "          total = response.json()[\"data\"]\n",
    "        except:\n",
    "          continue\n",
    "        tmp_price = getHotelPrice(total,h_name)\n",
    "        if tmp_price.empty:\n",
    "          continue\n",
    "        price_df = pd.concat([price_df, tmp_price])\n",
    "\n",
    "  return price_df\n",
    "\n",
    "def searchFood(zip,r):\n",
    "  loc = Zip2Loc(zip)\n",
    "  df = pd.DataFrame()\n",
    "  for food in food_lst:\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "            str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "            str(r)+\"&type=\"+food+\"&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "    if df.empty:\n",
    "      df = pd.json_normalize(resp_json_payload[\"results\"])  \n",
    "    else:\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "    while \"next_page_token\" in resp_json_payload:\n",
    "      time.sleep(3)\n",
    "      page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "      url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=\"+food+\"&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "      response = requests.get(url)\n",
    "      resp_json_payload = response.json()\n",
    "\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "  return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "def searchPlay(zip,r):\n",
    "  loc = Zip2Loc(zip)\n",
    "  df = pd.DataFrame()\n",
    "  for place in play_lst:\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "            str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "            str(r)+\"&type=\"+place+\"&hasNextPage=true&nextPage()=true&sensor=false&key=\"+key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "    if df.empty:\n",
    "      df = pd.json_normalize(resp_json_payload[\"results\"])  \n",
    "    else:\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "    while \"next_page_token\" in resp_json_payload:\n",
    "      time.sleep(3)\n",
    "      page2_token = resp_json_payload[\"next_page_token\"]        \n",
    "      url=\"https://maps.googleapis.com/maps/api/place/textsearch/json?location=\"+\\\n",
    "          str(loc[\"lat\"])+\"%2C\"+str(loc[\"lng\"])+\"&radius=\"+\\\n",
    "          str(r)+\"&type=\"+place+\"&pagetoken=\"+page2_token+\"&key=\"+key\n",
    "      response = requests.get(url)\n",
    "      resp_json_payload = response.json()\n",
    "\n",
    "      df2 = pd.json_normalize(resp_json_payload[\"results\"])\n",
    "      df = pd.concat([df,df2])\n",
    "  return df.drop_duplicates(\"place_id\")\n",
    "\n",
    "def upload2BigQuery(df,table):\n",
    "  new_col = [name.replace(\".\",\"_\") for name in list(df.columns)]\n",
    "  df.set_axis(new_col,axis = 1, inplace = True)\n",
    "  df.to_gbq(dataset+\".\"+table, project_id=project_id, if_exists='replace',progress_bar=True,credentials = credentials)\n",
    "\n",
    "\n",
    "def catchData(zip,r,search,check_in, check_out=None):\n",
    "  if check_in:\n",
    "    table_name = \"_\".join([search,str(zip),str(r),check_in])\n",
    "  else:\n",
    "    today = date.today()\n",
    "    out = today+timedelta(days=1)\n",
    "    checkIn = today.strftime(\"%Y-%m-%d\")\n",
    "    checkOut = out.strftime(\"%Y-%m-%d\")\n",
    "    table_name = \"_\".join([search,str(zip),str(r),checkIn])\n",
    "\n",
    "  if search == \"hotel\":\n",
    "    # df = searchLodging(zip,r)\n",
    "    df, hotel_info = getID(zip,r)\n",
    "    if check_in:\n",
    "      price_df = getAllPrice(df,check_in, check_out)\n",
    "    else:\n",
    "      price_df = getAllPrice(df,checkIn, checkOut)\n",
    "\n",
    "    upload2BigQuery(df,table_name)\n",
    "    upload2BigQuery(hotel_info,\"hotel_info\")\n",
    "    upload2BigQuery(price_df,\"HotelPrice_\"+checkIn)\n",
    "\n",
    "  elif search == \"restaurant\":\n",
    "    df = searchFood(zip,r)\n",
    "    upload2BigQuery(df,table_name)\n",
    "  elif search == \"play\":\n",
    "    df = searchPlay(zip,r)\n",
    "    upload2BigQuery(df,table_name)\n",
    "  else:\n",
    "    print(\"Wrong searching request, please use: \", searchType)\n",
    "\n",
    "def loadPrice(check_in):\n",
    "  print(\"load Hotel Price\")\n",
    "  price_dfname = \"finalproject.HotelPrice_\"+check_in\n",
    "  query = \"SELECT * FROM `\"+price_dfname+\"`\"\n",
    "\n",
    "  data_frame = pandas_gbq.read_gbq(\n",
    "    query,\n",
    "    project_id=project_id,credentials = credentials)\n",
    "  \n",
    "  update_price1 = [int(p.split(\" \")[1][1:].replace(\",\",\"\")) for p in data_frame[\"Price\"]]\n",
    "  data_frame[\"updatePrice\"] = update_price1\n",
    "  \n",
    "  update_roomType = []\n",
    "  update_name = []\n",
    "  update_price = []\n",
    "  for i in range(len(data_frame)):\n",
    "    room_type = data_frame.iloc[i][\"Room_type\"]\n",
    "    name = data_frame.iloc[i][\"name\"]\n",
    "    price = data_frame.iloc[i][\"updatePrice\"]\n",
    "    if \"Suite\" in room_type:\n",
    "      update_roomType.append(\"Suite\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"King\" in room_type:\n",
    "      update_roomType.append(\"King\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"Queen\" in room_type:\n",
    "      update_roomType.append(\"Queen\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    elif \"Double\" in room_type:\n",
    "      update_roomType.append(\"Double\")\n",
    "      update_name.append(name)\n",
    "      update_price.append(price)\n",
    "    # else:\n",
    "    #   print(room_type, data_frame.iloc[i][\"Price\"])\n",
    "  update_df = pd.DataFrame({\"name\": update_name, \"Type\":update_roomType, \"Price\": update_price})\n",
    "  update_df = update_df.groupby([\"name\",\"Type\"]).min(\"Price\").reset_index()\n",
    "  return update_df\n",
    "\n",
    "def loadPlace(zip, r, search,check_in):\n",
    "  table_name = \"_\".join([search,str(zip),str(r),check_in])\n",
    "  query = \"SELECT * FROM `finalproject.\"+table_name+\"`\"\n",
    "  # print(query)\n",
    "  df = pandas_gbq.read_gbq(query,project_id=project_id,credentials = credentials)\n",
    "  # df = pd.read_csv(table_name+\".csv\")\n",
    "  return df\n",
    "\n",
    "def loadData(zip, r, search, check_in):\n",
    "  if search == \"hotel\":\n",
    "    price_df = loadPrice(check_in = check_in)\n",
    "    hotel_df = loadPlace(zip,r,search,check_in = check_in)\n",
    "    return price_df, hotel_df\n",
    "  elif search == \"restaurant\" or search == \"play\":\n",
    "    df = loadPlace(zip,r,search, check_in = check_in)\n",
    "    return None, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUzI2ck3bOXR"
   },
   "source": [
    "## Algorithm design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1639716788978,
     "user": {
      "displayName": "Jiongxin Ye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjlb8M2dExnffwT6hq2paV8pUPM7GEKoUCpTKD5=s64",
      "userId": "14451865628790522467"
     },
     "user_tz": 300
    },
    "id": "lnNqgR27Ommv"
   },
   "outputs": [],
   "source": [
    "weight = {\n",
    "    \"price\":{\"no_require\":1, \"high\": -2,\"low\":2},\n",
    "    \"rating\": {\"no_require\": -1, \"high\": -2},\n",
    "    \"safety\": {\"no_require\":1, \"high\":-2} # all feature in same weight\n",
    "}\n",
    "def findOptimalCoef(requirement, items):\n",
    "  coef = {key:[] for key in items}\n",
    "  coef_name = {key:[] for key in items}\n",
    "  bed = None\n",
    "  for item in items:\n",
    "    req = requirement[item]\n",
    "    for key, value in req.items():\n",
    "      if key == \"bed\":\n",
    "        bed = value\n",
    "      elif key == \"rating\":\n",
    "        w = weight[key][value]\n",
    "        coef[item]+=[w,w]\n",
    "        coef_name[item].append(\"_\".join([\"user_rating\",value]))\n",
    "        coef_name[item].append(\"_\".join([\"review_number\",value]))\n",
    "      else:\n",
    "        w = weight[key][value]\n",
    "        coef[item].append(w)\n",
    "        coef_name[item].append(\"_\".join([key,value]))\n",
    "  if \"play\" in coef:\n",
    "    r = coef[\"play\"][0]\n",
    "    safe = coef[\"play\"][-1]\n",
    "    coef[\"twitter\"] = [r,safe]\n",
    "    coef_name[\"twitter\"] = [coef_name[\"play\"][0],coef_name[\"play\"][-1]]\n",
    "  return coef, coef_name, bed\n",
    "\n",
    "def minmax_norm(df):\n",
    "    return (df- df.min()) / (df.max() - df.min())\n",
    "\n",
    "def cleanDF(requirement, items,zip,r,check_in):\n",
    "  output = {}\n",
    "  coef, coef_name, bed = findOptimalCoef(requirement, items)\n",
    "  # load safety data:\n",
    "  safety_df = pd.read_csv(crime_path)[[\"ZIPCODE\",\"safety_level\"]]\n",
    "  safety_df[\"ZIPCODE\"] = safety_df[\"ZIPCODE\"].astype(str)\n",
    "  output[\"safety\"] = safety_df\n",
    "  if \"play\" in items:\n",
    "\n",
    "    twitter_df = pd.read_csv(twitter_path)[[\"acutal_name\",\"zipcode\",\"average_likes\",\"average_reweets\",\"positive_rate\",\"negative_rate\"]]\n",
    "    twitter_df[\"zipcode\"] = twitter_df[\"zipcode\"].astype(str)\n",
    "    twitter_df = twitter_df[twitter_df[\"zipcode\"] == zip]\n",
    "    twitter_df = pd.merge(twitter_df, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "    twitter_df[\"rate_gap\"] = twitter_df[\"positive_rate\"] - twitter_df[\"negative_rate\"]\n",
    "\n",
    "    df_input = twitter_df[[\"average_likes\",\"average_reweets\"]]\n",
    "    df_input = minmax_norm(df_input)\n",
    "    twitter_df = pd.concat([twitter_df[[\"acutal_name\",\"rate_gap\",\"safety_level\"]],df_input],axis=1)\n",
    "    twitter_df[\"total\"] = [twitter_df.iloc[t][\"average_likes\"]+twitter_df.iloc[t][\"average_reweets\"]+twitter_df.iloc[t][\"rate_gap\"] for t in range(len(twitter_df))]\n",
    "    twitter_df = twitter_df.fillna(0)\n",
    "    twitter_df[\"Z\"] = twitter_df[[\"total\",\"safety_level\"]].dot(coef[\"twitter\"])\n",
    "\n",
    "    output[\"twitter\"] = twitter_df\n",
    "    # print(twitter_df)\n",
    "\n",
    "  for search in items:\n",
    "    try:\n",
    "      df1, df2 = loadData(zip,r,search,check_in = check_in)\n",
    "    except:\n",
    "      catchData(zip, r, search,check_in = check_in)\n",
    "      df1, df2 = loadData(zip,r,search,check_in = check_in)\n",
    "    if search == \"hotel\":\n",
    "      # df1: hotel price\n",
    "      # df2: hotel detail\n",
    "      if bed:\n",
    "        df1= df1[df1[\"Type\"] == bed]\n",
    "      else:\n",
    "        df1 = df1.groupby(\"name\").min(\"Price\").reset_index()\n",
    "\n",
    "      output[\"hotel_price\"]= df1\n",
    "\n",
    "      tmp_hotel = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "      tmp_hotel[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_hotel[\"formatted_address\"]]\n",
    "      tmp_hotel = pd.merge(tmp_hotel, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "      tmp_hotel = pd.merge(tmp_hotel, df1, how = \"inner\", on = \"name\")\n",
    "      # normalized data\n",
    "      df_input = tmp_hotel[[\"rating\",\"user_ratings_total\",\"safety_level\",\"Price\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "      tmp_hotel = pd.concat([tmp_hotel[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "\n",
    "\n",
    "      tmp_hotel[\"Z\"] = tmp_hotel[[\"Price\",\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"hotel\"])\n",
    "\n",
    "      output[\"hotel\"] = tmp_hotel\n",
    "    elif search == \"restaurant\":\n",
    "      \n",
    "      tmp_restaurant = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "      tmp_restaurant = tmp_restaurant[pd.notnull(tmp_restaurant[\"price_level\"])]\n",
    "\n",
    "      tmp_restaurant[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_restaurant[\"formatted_address\"]]\n",
    "      tmp_restaurant = pd.merge(tmp_restaurant, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "\n",
    "      df_input = tmp_restaurant[[\"rating\",\"user_ratings_total\",\"price_level\",\"safety_level\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "\n",
    "      tmp_restaurant = pd.concat([tmp_restaurant[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "\n",
    "      tmp_restaurant[\"Z\"] = tmp_restaurant[[\"price_level\",\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"restaurant\"])\n",
    "\n",
    "      output[\"restaurant\"] = tmp_restaurant\n",
    "\n",
    "    elif search == \"play\":\n",
    "      tmp_play = df2[df2[\"business_status\"] == \"OPERATIONAL\"]\n",
    "\n",
    "      tmp_play[\"zipcode\"] = [ad.split(\" \")[-1] for ad in tmp_play[\"formatted_address\"]]\n",
    "      tmp_play = pd.merge(tmp_play, safety_df, how = \"inner\", left_on = \"zipcode\", right_on = \"ZIPCODE\")\n",
    "\n",
    "      df_input = tmp_play[[\"rating\",\"user_ratings_total\",\"safety_level\"]]\n",
    "      df_input = minmax_norm(df_input)\n",
    "\n",
    "      tmp_play = pd.concat([tmp_play[[\"formatted_address\",\"name\"]],df_input],axis=1)\n",
    "      tmp_play[\"Z\"] = tmp_play[[\"rating\",\"user_ratings_total\",\"safety_level\"]].dot(coef[\"play\"])\n",
    "\n",
    "      output[\"play\"] = tmp_play\n",
    "  return output\n",
    "\n",
    "def recommendPlace(requirement, items, zip, r, check_in,N):\n",
    "  dfs = cleanDF(requirement, items, zip,r,check_in)\n",
    "  output = {}\n",
    "  for item in items:\n",
    "    # print(key)\n",
    "    df = dfs[item]\n",
    "    min_N = df.nsmallest(N,['Z'])\n",
    "    output[item] = min_N\n",
    "  if \"play\" in items:\n",
    "    df = dfs[\"twitter\"]\n",
    "    min_N = df.nsmallest(N,['Z'])\n",
    "    output[\"twitter\"] = min_N\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 GET https://bigquery.googleapis.com/bigquery/v2/projects/big-data6893-335604/datasets/finalproject/tables/restaurant_10025_5000_2021-12-05?prettyPrint=false: Access Denied: Table big-data6893-335604:finalproject.restaurant_10025_5000_2021-12-05: Permission bigquery.tables.get denied on table big-data6893-335604:finalproject.restaurant_10025_5000_2021-12-05 (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas_gbq\\gbq.py\u001b[0m in \u001b[0;36mrun_query\u001b[1;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Requesting query... \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             query_reply = self.client.query(\n\u001b[0m\u001b[0;32m    414\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m   3334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3335\u001b[1;33m         \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3336\u001b[0m         \u001b[1;31m# The future might be in a failed state now, but if it's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36mdo_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3311\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3312\u001b[1;33m                 \u001b[0mquery_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3313\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConflict\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcreate_exc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py\u001b[0m in \u001b[0;36m_begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py\u001b[0m in \u001b[0;36m_begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"path\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         api_response = client._call_api(\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36m_call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    759\u001b[0m             ):\n\u001b[1;32m--> 760\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m             )\n\u001b[1;32m--> 283\u001b[1;33m             return retry_target(\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/big-data6893-335604/jobs?prettyPrint=false: Access Denied: Project big-data6893-335604: User does not have bigquery.jobs.create permission in project big-data6893-335604.\n\n(job ID: dbe91afc-6664-41a5-88e2-96ab25f8db99)\n\n                 -----Query Job SQL Follows-----                  \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT * FROM `finalproject.restaurant_10025_5000_2021-12-05`\n    |    .    |    .    |    .    |    .    |    .    |    .    |",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mGenericGBQException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/4112926059.py\u001b[0m in \u001b[0;36mcleanDF\u001b[1;34m(requirement, items, zip, r, check_in)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m       \u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/819332477.py\u001b[0m in \u001b[0;36mloadData\u001b[1;34m(zip, r, search, check_in)\u001b[0m\n\u001b[0;32m    392\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"restaurant\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"play\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadPlace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/819332477.py\u001b[0m in \u001b[0;36mloadPlace\u001b[1;34m(zip, r, search, check_in)\u001b[0m\n\u001b[0;32m    382\u001b[0m   \u001b[1;31m# print(query)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas_gbq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m   \u001b[1;31m# df = pd.read_csv(table_name+\".csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas_gbq\\gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[1;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type, dtypes)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m     final_df = connector.run_query(\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas_gbq\\gbq.py\u001b[0m in \u001b[0;36mrun_query\u001b[1;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp_error\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_http_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas_gbq\\gbq.py\u001b[0m in \u001b[0;36mprocess_http_error\u001b[1;34m(ex)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mGenericGBQException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reason: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mGenericGBQException\u001b[0m: Reason: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/big-data6893-335604/jobs?prettyPrint=false: Access Denied: Project big-data6893-335604: User does not have bigquery.jobs.create permission in project big-data6893-335604.\n\n(job ID: dbe91afc-6664-41a5-88e2-96ab25f8db99)\n\n                 -----Query Job SQL Follows-----                  \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:SELECT * FROM `finalproject.restaurant_10025_5000_2021-12-05`\n    |    .    |    .    |    .    |    .    |    .    |    .    |",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/3628140289.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrequirement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'restaurant'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'safety'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'play'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'safety'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'high'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"restaurant\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"play\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecommendPlace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"10025\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"2021-12-05\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/4112926059.py\u001b[0m in \u001b[0;36mrecommendPlace\u001b[1;34m(requirement, items, zip, r, check_in, N)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecommendPlace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m   \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m   \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/4112926059.py\u001b[0m in \u001b[0;36mcleanDF\u001b[1;34m(requirement, items, zip, r, check_in)\u001b[0m\n\u001b[0;32m     61\u001b[0m       \u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m       \u001b[0mcatchData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m       \u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheck_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"hotel\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/819332477.py\u001b[0m in \u001b[0;36mcatchData\u001b[1;34m(zip, r, search, check_in, check_out)\u001b[0m\n\u001b[0;32m    329\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"restaurant\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearchFood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m     \u001b[0mupload2BigQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"play\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearchPlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JIANGA~1\\AppData\\Local\\Temp/ipykernel_20604/819332477.py\u001b[0m in \u001b[0;36mupload2BigQuery\u001b[1;34m(df, table)\u001b[0m\n\u001b[0;32m    302\u001b[0m   \u001b[0mnew_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m   \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m   \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_gbq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproject_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_gbq\u001b[1;34m(self, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[0;32m   1927\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgbq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m         gbq.to_gbq(\n\u001b[0m\u001b[0;32m   1930\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m             \u001b[0mdestination_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas\\io\\gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[1;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[0;32m    210\u001b[0m ) -> None:\n\u001b[0;32m    211\u001b[0m     \u001b[0mpandas_gbq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     pandas_gbq.to_gbq(\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mdestination_table\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\pandas_gbq\\gbq.py\u001b[0m in \u001b[0;36mto_gbq\u001b[1;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, verbose, private_key)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;31m# If table exists, check if_exists parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbqclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestination_table_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mgoogle_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         table_connector = _Table(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36mget_table\u001b[1;34m(self, table, retry, timeout)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"path\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         api_response = self._call_api(\n\u001b[0m\u001b[0;32m   1015\u001b[0m             \u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"BigQuery.getTable\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\bigquery\\client.py\u001b[0m in \u001b[0;36m_call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    758\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             ):\n\u001b[1;32m--> 760\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             )\n\u001b[1;32m--> 283\u001b[1;33m             return retry_target(\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\api_core\\retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python3\\lib\\site-packages\\google\\cloud\\_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/big-data6893-335604/datasets/finalproject/tables/restaurant_10025_5000_2021-12-05?prettyPrint=false: Access Denied: Table big-data6893-335604:finalproject.restaurant_10025_5000_2021-12-05: Permission bigquery.tables.get denied on table big-data6893-335604:finalproject.restaurant_10025_5000_2021-12-05 (or it may not exist)."
     ]
    }
   ],
   "source": [
    "requirement = {'restaurant': {'price': 'high', 'rating': 'high', 'safety': 'high'}, 'play': {'rating': 'high', 'safety': 'high'}}\n",
    "items = [\"restaurant\", \"play\"]\n",
    "data = recommendPlace(requirement, items, \"10025\", 5000, \"2021-12-05\",3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PlaceSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
